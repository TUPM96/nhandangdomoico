# Há»‡ Thá»‘ng Nháº­n Dáº¡ng Má»i CÆ¡ - LDA, KNN, SVM

Há»‡ thá»‘ng AI nháº­n dáº¡ng má»i cÆ¡ sá»­ dá»¥ng 3 phÆ°Æ¡ng phÃ¡p Machine Learning: **LDA** (Linear Discriminant Analysis), **KNN** (K-Nearest Neighbors), vÃ  **SVM** (Support Vector Machine).

## ğŸ¯ Má»¥c TiÃªu

XÃ¢y dá»±ng há»‡ thá»‘ng nháº­n dáº¡ng má»i cÆ¡ vá»›i Ä‘á»™ chÃ­nh xÃ¡c **85-95%** trÃªn test set.

## ğŸ“‹ YÃªu Cáº§u Há»‡ Thá»‘ng

- Python 3.7+
- CÃ¡c thÆ° viá»‡n trong `requirements_new.txt`

## ğŸš€ CÃ i Äáº·t

### 1. Clone repository (hoáº·c táº£i vá»)

```bash
git clone <repository-url>
cd nhandangdomoico
```

### 2. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements_new.txt
```

## ğŸ“Š Dá»¯ Liá»‡u

Há»‡ thá»‘ng sá»­ dá»¥ng 10 features Ä‘á»ƒ nháº­n dáº¡ng má»i cÆ¡:

| Feature | MÃ´ táº£ | ÄÆ¡n vá»‹ |
|---------|-------|--------|
| `emg_rms` | Root Mean Square cá»§a tÃ­n hiá»‡u EMG | mV |
| `emg_mav` | Mean Absolute Value cá»§a tÃ­n hiá»‡u EMG | mV |
| `emg_median_freq` | Táº§n sá»‘ trung vá»‹ cá»§a tÃ­n hiá»‡u EMG | Hz |
| `emg_mean_freq` | Táº§n sá»‘ trung bÃ¬nh cá»§a tÃ­n hiá»‡u EMG | Hz |
| `muscle_force` | Lá»±c cÆ¡ | N (Newton) |
| `heart_rate` | Nhá»‹p tim | bpm |
| `work_duration` | Thá»i gian lÃ m viá»‡c | phÃºt |
| `rest_time` | Thá»i gian nghá»‰ ngÆ¡i | phÃºt |
| `movement_frequency` | Táº§n sá»‘ chuyá»ƒn Ä‘á»™ng | láº§n/phÃºt |
| `muscle_tension` | Äá»™ cÄƒng cÆ¡ | 0-100 |

**2 Classes:**
- `0`: Non-Fatigue (KhÃ´ng má»i)
- `1`: Fatigue (Má»i)

## ğŸ”§ CÃ¡ch Sá»­ Dá»¥ng

### PhÆ°Æ¡ng PhÃ¡p 1: Cháº¡y ToÃ n Bá»™ Pipeline (Khuyáº¿n Nghá»‹)

Cháº¡y tá»« generate data â†’ train â†’ test trong má»™t lá»‡nh duy nháº¥t:

```bash
python run_full_pipeline.py
```

**TÃ¹y chá»n nÃ¢ng cao:**

```bash
# Táº¡o 3000 máº«u, test size 30%, sá»­ dá»¥ng GridSearchCV
python run_full_pipeline.py --n-samples 3000 --test-size 0.3

# Train nhanh (khÃ´ng dÃ¹ng GridSearchCV)
python run_full_pipeline.py --no-grid-search

# Thay Ä‘á»•i random seed
python run_full_pipeline.py --seed 123
```

### PhÆ°Æ¡ng PhÃ¡p 2: Cháº¡y Tá»«ng BÆ°á»›c

#### BÆ°á»›c 1: Generate Data

```bash
python generate_data.py
```

Táº¡o ra:
- `data_generated/train_data.csv` (1500 máº«u)
- `data_generated/test_data.csv` (500 máº«u)
- `data_generated/full_data.csv` (2000 máº«u)

#### BÆ°á»›c 2: Train Models

```bash
python train_models.py
```

Train cáº£ 3 models (LDA, KNN, SVM) vÃ  lÆ°u vÃ o thÆ° má»¥c `models/`:
- `lda_model.pkl`
- `knn_model.pkl`
- `svm_model.pkl`
- `model_comparison.csv`
- `all_results.json`

Confusion matrices Ä‘Æ°á»£c lÆ°u trong `plots/`.

#### BÆ°á»›c 3: Test Models

```bash
# Test táº¥t cáº£ models
python test_models.py

# Test má»™t model cá»¥ thá»ƒ
python test_models.py --model svm
python test_models.py --model knn
python test_models.py --model lda

# Chá»‰ Ä‘á»‹nh path
python test_models.py --test-data data_generated/test_data.csv --models-dir models
```

## ğŸ“ˆ Káº¿t Quáº£ Mong Äá»£i

Sau khi cháº¡y, báº¡n sáº½ tháº¥y:

```
SO SÃNH Káº¾T QUáº¢ TEST
============================================================
           Accuracy  Precision    Recall  F1-Score
lda        0.9120     0.9180    0.9050    0.9115
knn        0.8980     0.9020    0.8940    0.8980
svm        0.9340     0.9390    0.9290    0.9340

âœ“ Model tá»‘t nháº¥t: SVM
âœ“ Accuracy: 0.9340 (93.40%)

âœ“âœ“âœ“ Äáº T Má»¤C TIÃŠU! Accuracy >= 85% âœ“âœ“âœ“
```

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
.
â”œâ”€â”€ generate_data.py          # Script táº¡o synthetic data
â”œâ”€â”€ train_models.py            # Script train models
â”œâ”€â”€ test_models.py             # Script test models
â”œâ”€â”€ run_full_pipeline.py       # Script cháº¡y toÃ n bá»™ pipeline
â”œâ”€â”€ requirements_new.txt       # Dependencies
â”œâ”€â”€ README_NEW.md              # TÃ i liá»‡u nÃ y
â”‚
â”œâ”€â”€ data_generated/            # Dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o
â”‚   â”œâ”€â”€ train_data.csv
â”‚   â”œâ”€â”€ test_data.csv
â”‚   â””â”€â”€ full_data.csv
â”‚
â”œâ”€â”€ models/                    # Models Ä‘Ã£ train
â”‚   â”œâ”€â”€ lda_model.pkl
â”‚   â”œâ”€â”€ knn_model.pkl
â”‚   â”œâ”€â”€ svm_model.pkl
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â””â”€â”€ all_results.json
â”‚
â”œâ”€â”€ plots/                     # Confusion matrices
â”‚   â”œâ”€â”€ lda_confusion_matrix.png
â”‚   â”œâ”€â”€ knn_confusion_matrix.png
â”‚   â””â”€â”€ svm_confusion_matrix.png
â”‚
â””â”€â”€ test_results/              # Káº¿t quáº£ test
    â”œâ”€â”€ test_comparison.csv
    â””â”€â”€ models_comparison.png
```

## ğŸ” Chi Tiáº¿t Models

### 1. LDA (Linear Discriminant Analysis)

**Æ¯u Ä‘iá»ƒm:**
- Nhanh, hiá»‡u quáº£
- Tá»‘t vá»›i dá»¯ liá»‡u tuyáº¿n tÃ­nh
- Giáº£m chiá»u dá»¯ liá»‡u tá»± Ä‘á»™ng

**Hyperparameters Ä‘Æ°á»£c tune:**
- `solver`: svd, lsqr, eigen
- `shrinkage`: None, auto, 0.1, 0.5, 0.9

### 2. KNN (K-Nearest Neighbors)

**Æ¯u Ä‘iá»ƒm:**
- ÄÆ¡n giáº£n, dá»… hiá»ƒu
- KhÃ´ng cáº§n training phase
- Tá»‘t vá»›i decision boundaries phá»©c táº¡p

**Hyperparameters Ä‘Æ°á»£c tune:**
- `n_neighbors`: 3, 5, 7, 9, 11, 15
- `weights`: uniform, distance
- `metric`: euclidean, manhattan, minkowski

### 3. SVM (Support Vector Machine)

**Æ¯u Ä‘iá»ƒm:**
- Hiá»‡u quáº£ vá»›i high-dimensional data
- Tá»‘t vá»›i margin rÃµ rÃ ng
- Sá»­ dá»¥ng kernel trick cho non-linear problems

**Hyperparameters Ä‘Æ°á»£c tune:**
- `C`: 0.1, 1, 10, 100
- `kernel`: rbf, linear, poly
- `gamma`: scale, auto, 0.001, 0.01, 0.1, 1

## ğŸ›ï¸ TÃ¹y Chá»‰nh

### Táº¡o nhiá»u dá»¯ liá»‡u hÆ¡n

Sá»­a trong `generate_data.py`:

```python
train_df, test_df, full_df = save_train_test_data(
    output_dir='data_generated',
    n_samples=5000,  # TÄƒng lÃªn 5000
    test_size=0.25,
    seed=42
)
```

### Thay Ä‘á»•i Hyperparameters

Sá»­a trong `train_models.py`, hÃ m `get_param_grid()`:

```python
def get_param_grid(self):
    if self.model_type == 'svm':
        return {
            'C': [0.1, 1, 10, 100, 1000],  # ThÃªm giÃ¡ trá»‹
            'kernel': ['rbf', 'linear'],
            'gamma': ['scale', 'auto', 0.0001, 0.001, 0.01]
        }
```

### ThÃªm Features Má»›i

Sá»­a trong `generate_data.py`, hÃ m `generate_fatigue_muscle_data()`:

```python
non_fatigue_data = {
    # ... features hiá»‡n cÃ³ ...
    'new_feature': np.random.normal(50, 10, n_non_fatigue),
}
```

## ğŸ› Troubleshooting

### Lá»—i: Module not found

```bash
pip install -r requirements_new.txt
```

### Accuracy tháº¥p hÆ¡n 85%

1. TÄƒng sá»‘ lÆ°á»£ng samples:
   ```bash
   python run_full_pipeline.py --n-samples 5000
   ```

2. Äáº£m báº£o GridSearchCV Ä‘Æ°á»£c báº­t (máº·c Ä‘á»‹nh)

3. Thá»­ cÃ¡c random seeds khÃ¡c:
   ```bash
   python run_full_pipeline.py --seed 123
   python run_full_pipeline.py --seed 456
   ```

### Training quÃ¡ cháº­m

1. Táº¯t GridSearchCV:
   ```bash
   python run_full_pipeline.py --no-grid-search
   ```

2. Giáº£m sá»‘ lÆ°á»£ng samples:
   ```bash
   python run_full_pipeline.py --n-samples 1000
   ```

## ğŸ“Š Sá»­ Dá»¥ng Model ÄÃ£ Train

```python
from train_models import FatigueMuscleClassifier
import numpy as np

# Load model
classifier = FatigueMuscleClassifier.load_model('models/svm_model.pkl')

# Dá»¯ liá»‡u máº«u (1 sample vá»›i 10 features)
sample = np.array([[
    0.25,  # emg_rms
    0.20,  # emg_mav
    65,    # emg_median_freq
    70,    # emg_mean_freq
    35,    # muscle_force
    95,    # heart_rate
    40,    # work_duration
    3,     # rest_time
    12,    # movement_frequency
    70     # muscle_tension
]])

# Transform vÃ  predict
sample_scaled = classifier.scaler.transform(sample)
prediction = classifier.model.predict(sample_scaled)[0]

print(f"Prediction: {'Fatigue' if prediction == 1 else 'Non-Fatigue'}")
```

## ğŸ“ License

MIT License

## ğŸ‘¥ Authors

Há»‡ thá»‘ng nháº­n dáº¡ng má»i cÆ¡ - AI/ML Project

## ğŸ™ Acknowledgments

- scikit-learn documentation
- EMG signal processing research papers
- Machine learning best practices

---

**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**

Náº¿u cÃ³ váº¥n Ä‘á», hÃ£y kiá»ƒm tra logs hoáº·c má»Ÿ issue.
