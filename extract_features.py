"""
Extract features tá»« raw EMG dataset gá»‘c
Input: EMG time-series tá»« dataset/fatigue/ vÃ  dataset/non fatigue/
Output: CSV file vá»›i extracted features
"""

import numpy as np
import pandas as pd
import os
from scipy import signal
from scipy.stats import kurtosis, skew
import glob

def extract_emg_features(emg_signal, sampling_rate=1000):
    """
    Extract features tá»« EMG time-series signal

    Parameters:
    -----------
    emg_signal : array-like
        Raw EMG signal (amplitudo values)
    sampling_rate : int
        Sampling rate (Hz), default 1000Hz

    Returns:
    --------
    dict : Dictionary chá»©a cÃ¡c features
    """
    # Ensure numpy array
    emg_signal = np.array(emg_signal)

    # Remove mean (DC offset)
    emg_signal = emg_signal - np.mean(emg_signal)

    features = {}

    # ============ TIME-DOMAIN FEATURES ============

    # 1. Root Mean Square (RMS)
    features['emg_rms'] = np.sqrt(np.mean(emg_signal ** 2))

    # 2. Mean Absolute Value (MAV)
    features['emg_mav'] = np.mean(np.abs(emg_signal))

    # 3. Variance
    features['emg_variance'] = np.var(emg_signal)

    # 4. Standard Deviation
    features['emg_std'] = np.std(emg_signal)

    # 5. Waveform Length (WL)
    features['emg_waveform_length'] = np.sum(np.abs(np.diff(emg_signal)))

    # 6. Zero Crossing (ZC) - sá»‘ láº§n tÃ­n hiá»‡u cross zero
    zero_crossings = np.where(np.diff(np.sign(emg_signal)))[0]
    features['emg_zero_crossing'] = len(zero_crossings)

    # 7. Slope Sign Changes (SSC)
    diff_signal = np.diff(emg_signal)
    ssc = np.sum(np.diff(np.sign(diff_signal)) != 0)
    features['emg_ssc'] = ssc

    # 8. Kurtosis (measure of "tailedness")
    features['emg_kurtosis'] = kurtosis(emg_signal)

    # 9. Skewness (measure of asymmetry)
    features['emg_skewness'] = skew(emg_signal)

    # 10. Peak Value
    features['emg_peak'] = np.max(np.abs(emg_signal))

    # ============ FREQUENCY-DOMAIN FEATURES ============

    # Compute Power Spectral Density using Welch's method
    freqs, psd = signal.welch(emg_signal, fs=sampling_rate, nperseg=min(256, len(emg_signal)))

    # 11. Median Frequency (MDF)
    cumsum_psd = np.cumsum(psd)
    total_power = cumsum_psd[-1]
    median_idx = np.where(cumsum_psd >= total_power / 2)[0]
    if len(median_idx) > 0:
        features['emg_median_freq'] = freqs[median_idx[0]]
    else:
        features['emg_median_freq'] = 0

    # 12. Mean Frequency (MNF)
    features['emg_mean_freq'] = np.sum(freqs * psd) / np.sum(psd)

    # 13. Peak Frequency
    peak_freq_idx = np.argmax(psd)
    features['emg_peak_freq'] = freqs[peak_freq_idx]

    # 14. Total Power
    features['emg_total_power'] = np.sum(psd)

    # 15. Power in specific bands
    # Low freq band (0-50Hz)
    low_band_mask = (freqs >= 0) & (freqs < 50)
    features['emg_power_low'] = np.sum(psd[low_band_mask])

    # Mid freq band (50-150Hz)
    mid_band_mask = (freqs >= 50) & (freqs < 150)
    features['emg_power_mid'] = np.sum(psd[mid_band_mask])

    # High freq band (150-500Hz)
    high_band_mask = (freqs >= 150) & (freqs < 500)
    features['emg_power_high'] = np.sum(psd[high_band_mask])

    return features

def process_emg_file(file_path, label, label_name):
    """
    Xá»­ lÃ½ má»™t file EMG vÃ  extract features

    Parameters:
    -----------
    file_path : str
        Path Ä‘áº¿n EMG CSV file
    label : int
        Label (0=Non-Fatigue, 1=Fatigue)
    label_name : str
        TÃªn label

    Returns:
    --------
    dict : Features dictionary vá»›i label
    """
    try:
        # Äá»c CSV
        df = pd.read_csv(file_path)

        # TÃ¬m cá»™t chá»©a EMG data (cÃ³ thá»ƒ lÃ  'amplitudo', hoáº·c cá»™t cuá»‘i)
        if 'amplitudo' in df.columns:
            emg_data = df['amplitudo'].values
        else:
            # Láº¥y cá»™t cuá»‘i cÃ¹ng (thÆ°á»ng lÃ  EMG data)
            emg_data = df.iloc[:, -1].values

        # Remove NaN
        emg_data = emg_data[~np.isnan(emg_data)]

        # Extract features
        features = extract_emg_features(emg_data)

        # ThÃªm label
        features['label'] = label
        features['class_name'] = label_name
        features['file_name'] = os.path.basename(file_path)

        return features

    except Exception as e:
        print(f"âŒ Error processing {file_path}: {e}")
        return None

def extract_all_features(dataset_dir='dataset', output_dir='data_extracted'):
    """
    Extract features tá»« táº¥t cáº£ EMG files

    Parameters:
    -----------
    dataset_dir : str
        ThÆ° má»¥c chá»©a dataset
    output_dir : str
        ThÆ° má»¥c lÆ°u features extracted
    """
    print("="*70)
    print(" "*15 + "EXTRACT FEATURES Tá»ª DATASET Gá»C")
    print("="*70)

    # Paths
    fatigue_dir = os.path.join(dataset_dir, 'fatigue')
    non_fatigue_dir = os.path.join(dataset_dir, 'non fatigue')

    # Táº¡o output dir
    os.makedirs(output_dir, exist_ok=True)

    all_features = []

    # ========== Xá»¬ LÃ FATIGUE FILES ==========
    print(f"\nðŸ“ Äang xá»­ lÃ½ Fatigue files tá»« {fatigue_dir}...")
    fatigue_files = glob.glob(os.path.join(fatigue_dir, '*.csv'))
    print(f"   TÃ¬m tháº¥y {len(fatigue_files)} files")

    for i, file_path in enumerate(fatigue_files, 1):
        print(f"   [{i}/{len(fatigue_files)}] Processing: {os.path.basename(file_path)}", end='')
        features = process_emg_file(file_path, label=1, label_name='Fatigue')
        if features:
            all_features.append(features)
            print(" âœ“")
        else:
            print(" âœ—")

    # ========== Xá»¬ LÃ NON-FATIGUE FILES ==========
    print(f"\nðŸ“ Äang xá»­ lÃ½ Non-Fatigue files tá»« {non_fatigue_dir}...")
    non_fatigue_files = glob.glob(os.path.join(non_fatigue_dir, '*.csv'))
    print(f"   TÃ¬m tháº¥y {len(non_fatigue_files)} files")

    for i, file_path in enumerate(non_fatigue_files, 1):
        print(f"   [{i}/{len(non_fatigue_files)}] Processing: {os.path.basename(file_path)}", end='')
        features = process_emg_file(file_path, label=0, label_name='Non-Fatigue')
        if features:
            all_features.append(features)
            print(" âœ“")
        else:
            print(" âœ—")

    # ========== Táº O DATAFRAME ==========
    print(f"\nðŸ“Š Táº¡o DataFrame...")
    df = pd.DataFrame(all_features)

    # Shuffle
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)

    # LÆ°u file
    output_path = os.path.join(output_dir, 'extracted_features.csv')
    df.to_csv(output_path, index=False)

    print(f"\n{'='*70}")
    print("THá»NG KÃŠ")
    print('='*70)
    print(f"\nTá»•ng sá»‘ files: {len(all_features)}")
    print(f"  - Fatigue: {(df['label']==1).sum()} files")
    print(f"  - Non-Fatigue: {(df['label']==0).sum()} files")

    print(f"\nSá»‘ features: {len(df.columns) - 3}")  # Trá»« label, class_name, file_name

    # Feature columns
    feature_cols = [col for col in df.columns if col not in ['label', 'class_name', 'file_name']]
    print(f"\nFeatures extracted:")
    for i, col in enumerate(feature_cols, 1):
        print(f"  {i:2d}. {col}")

    print(f"\nâœ“ ÄÃ£ lÆ°u features táº¡i: {output_path}")

    # Thá»‘ng kÃª chi tiáº¿t
    print(f"\n{'='*70}")
    print("THá»NG KÃŠ FEATURES THEO CLASS")
    print('='*70)

    stats_by_class = df.groupby('class_name')[feature_cols].agg(['mean', 'std'])
    print("\nMean values:")
    print(df.groupby('class_name')[feature_cols[:5]].mean().round(2))

    # PhÃ¢n bá»‘
    print(f"\nPhÃ¢n bá»‘:")
    print(df['class_name'].value_counts())

    return df

def create_train_test_split(input_csv='data_extracted/extracted_features.csv',
                            output_dir='data_extracted',
                            test_size=0.25,
                            random_state=42):
    """
    Chia train/test tá»« extracted features
    """
    from sklearn.model_selection import train_test_split

    print(f"\n{'='*70}")
    print("CHIA TRAIN/TEST SET")
    print('='*70)

    # Load data
    df = pd.read_csv(input_csv)

    # TÃ¡ch features vÃ  labels
    feature_cols = [col for col in df.columns if col not in ['label', 'class_name', 'file_name']]
    X = df[feature_cols]
    y = df['label']

    # Chia train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )

    # Táº¡o DataFrames
    train_df = X_train.copy()
    train_df['label'] = y_train
    train_df['class_name'] = train_df['label'].map({0: 'Non-Fatigue', 1: 'Fatigue'})

    test_df = X_test.copy()
    test_df['label'] = y_test
    test_df['class_name'] = test_df['label'].map({0: 'Non-Fatigue', 1: 'Fatigue'})

    # LÆ°u files
    train_path = os.path.join(output_dir, 'train_data.csv')
    test_path = os.path.join(output_dir, 'test_data.csv')

    train_df.to_csv(train_path, index=False)
    test_df.to_csv(test_path, index=False)

    print(f"\nâœ“ Train set: {len(train_df)} samples â†’ {train_path}")
    print(f"  - Non-Fatigue: {(train_df['label']==0).sum()}")
    print(f"  - Fatigue: {(train_df['label']==1).sum()}")

    print(f"\nâœ“ Test set: {len(test_df)} samples â†’ {test_path}")
    print(f"  - Non-Fatigue: {(test_df['label']==0).sum()}")
    print(f"  - Fatigue: {(test_df['label']==1).sum()}")

    return train_df, test_df

if __name__ == "__main__":
    # Extract features tá»« dataset gá»‘c
    df = extract_all_features(
        dataset_dir='dataset',
        output_dir='data_extracted'
    )

    # Chia train/test
    train_df, test_df = create_train_test_split(
        input_csv='data_extracted/extracted_features.csv',
        output_dir='data_extracted',
        test_size=0.25
    )

    print(f"\n{'='*70}")
    print("âœ“ HOÃ€N Táº¤T!")
    print('='*70)
    print("\nBÆ°á»›c tiáº¿p theo:")
    print("  python train_models.py  # Train vá»›i data thá»±c")
